{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unrP0oFltz-9",
        "outputId": "467ca52d-a128-4fb0-efc2-e1249890ab07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Complete\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "print(\"Complete\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import csv\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "62HEW-M7t7Sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Data"
      ],
      "metadata": {
        "id": "MfyJNfJYug3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file = '1010408_2_4.csv'\n",
        "# csv_file = '1137737.csv'\n",
        "dest = '/content/gdrive/MyDrive/WPI/Research/Quick Comments/'\n",
        "\n",
        "csv_path = os.path.join(dest, csv_file)\n",
        "csv_df = pd.read_csv(csv_path)"
      ],
      "metadata": {
        "id": "-NSIyW06uEGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMUJ2OfiI6En",
        "outputId": "d3704fed-e022-4d38-aba5-91b91031eb93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1104, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_df = csv_df.dropna(axis=0)"
      ],
      "metadata": {
        "id": "RUVB66yhI8Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Model"
      ],
      "metadata": {
        "id": "Wyi2_52ZuknN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmFve5X14U23",
        "outputId": "5ea0a88d-d8ae-4613-9c17-e450677d86c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 21.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 89.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 88.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.0 tokenizers-0.13.2 transformers-4.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoConfig, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "QvjxnIoq4g5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "K95nuSfjQZRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_models = [\n",
        "    \"bigscience/bloom-560m\",\n",
        "    \"bigscience/bloom-1b1\",\n",
        "    \"bigscience/bloom-1b7\",\n",
        "    \"bigscience/bloom-3b\",\n",
        "    \"bigscience/bloom-7b1\",  \n",
        "    \"facebook/opt-125m\",\n",
        "    \"facebook/opt-350m\"\n",
        "    \"facebook/opt-1.3b\",\n",
        "    \"facebook/opt-2.7b\",\n",
        "    \"facebook/opt-6.7b\",\n",
        "    \"facebook/opt-13b\",\n",
        "    \"facebook/opt-66b\",\n",
        "    \"xlnet-large-cased\",\n",
        "    \"tbs17/MathBERT\",\n",
        "    \"witiko/mathberta\",\n",
        "    \"google/flan-t5-xxl\",\n",
        "    \"t5-base\"\n",
        "]"
      ],
      "metadata": {
        "id": "iGs-W26l59hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        ")"
      ],
      "metadata": {
        "id": "Oa6GfOooQ5HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logs = {'model': [], 'problem_log_id': [], 'prompt':[], 'pred':[], 'actual':[]}\n",
        "device = torch.device('cuda', 0)\n",
        "\n",
        "\n",
        "\n",
        "for model_name in tqdm(list_of_models):\n",
        "    # Download configuration from huggingface.co and cache.\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    def preprocess_function(examples):\n",
        "        return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_imdb[\"train\"],\n",
        "        eval_dataset=tokenized_imdb[\"test\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    for entry in tqdm(csv_df.iterrows(), total = csv_df.shape[0]):\n",
        "        selected_problem = entry[1]\n",
        "        prompt = selected_problem['prompt']\n",
        "        output = classifier(\n",
        "            prompt,\n",
        "            candidate_labels=['0', '1', '2', '3', '4'],\n",
        "        )\n",
        "\n",
        "        logs['model'] = [model]\n",
        "        logs['problem_log_id'] = selected_problem['problem_log_id']\n",
        "        logs['prompt'] += [output['sequence']]\n",
        "        logs['pred'] += [[output['scores']]]\n",
        "        logs['actual'] += [selected_problem['correctness']]\n",
        "        # print(f'pred: {output['scores']}, actual: {score}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192,
          "referenced_widgets": [
            "a5122bdc2fb543ceac7302c8c64e6940",
            "09ec5fc6d867456bbca64cd39a2b7699",
            "5c4b167910734b9593dc53d2f2df70bf",
            "2e0a6f638c5d466aaf9b54010dfbf1da",
            "f9c1d69b4b394ea9b8409e0beb67b348",
            "913bc12ba12b454d9e7fa6250a02f102",
            "a0d611f8de514e3ca1d290eedc7ee5f6",
            "8d0837d45d084f69ac3e968d7d4671ed",
            "91335b1b781f47d38bd2500bf6c3a554",
            "a029a065f3434f51bea0ebb8bb4d4c0e",
            "f67bc02a11db41b28770615fc0cc9298",
            "0c2f85047ee444ddb9b46814c353d07d",
            "7b68017a7f294c21968b376711da4939",
            "57c8e3c9796942958e0e4de05676babf",
            "cf9795b1ad7944f990db96f98f091ade",
            "7574ddb4bd204d41a558db296675ccea",
            "383282f63d5e45329f1af41801e04106",
            "3088a39b8e0347e89033a759e8d5cd20",
            "3b21a411eb3d49c4ab7e3cdae6f0329d",
            "5ae4a5269b014911b3c67ac118c7fd7d",
            "34d20a9bdd5a443786e3a03c2c99c8b1",
            "97a67e72ee2a46888c7752ec27c9ea32"
          ]
        },
        "id": "nMoty4Fq31R2",
        "outputId": "7695ddee-d030-4859-95af-48aa8558d243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/16 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5122bdc2fb543ceac7302c8c64e6940"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1094 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c2f85047ee444ddb9b46814c353d07d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py:1046: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  UserWarning,\n"
          ]
        }
      ]
    }
  ]
}